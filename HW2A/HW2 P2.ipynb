{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Problem 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### A) Prove that E step update on membership (\\pi) achieves the minimum objective given the current centroids( \\mu)\n",
    "\n",
    "By updating the membership, we can move some datapoints to other appropriate cluster. By doing this, we can position each datapoint to the nearest centroid. If E step doesn't update on membership achieves the minimum objective, than the objective would remain the same or increase and wouldn't be placed near the closest centroid.\n",
    "\n",
    "#### Add) Given a datapoints X, argmin function minimizes the within-cluster sum of square of difference between each datapoint and the centroid.\n",
    "\n",
    "\n",
    "\n",
    "### B) Prove that M step update on centroids (\\mu) achievess the minimum objective given the current memberships( \\pi)\n",
    "\n",
    "In the M-Step, mean minimizes total distance given the current clustering: M-step uses argmin function that returns the minimum value from the given axis. By going through EM loop as a whole, the objective always decreases. To make an optimal solution it is necessary to minimize the summed distance between every point and its centroid.\n",
    "\n",
    "#### Add) Take partial derivative of Î¼k and set to zero\n",
    "\n",
    "### C) Explain why KMeans has to stop (converge), but not necessarily to the global minimum objective value.\n",
    "\n",
    "The objective function optimized by the K-Means is not convex. It suffers from many local optima and it is sensitive to the initial mu and pi values. When we're given the bad seed in the first place, there's a high possibility it will result in bad clustering result with poor convergence.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Problem 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from keras.datasets import mnist\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "source": [
    "## Section A - MNIST"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 784)\n(60000,)\n(10000, 784)\n(10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = normalize(X_train.reshape(60000, 784))\n",
    "X_test = normalize(X_test.reshape(10000, 784))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(digit, title = \"\"):\n",
    "    \"\"\"\n",
    "    graphically displays a 784x1 vector, representing a digit\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    fig = plt.imshow(digit)\n",
    "    fig.set_cmap('gray_r')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    if title != \"\":\n",
    "        plt.title(\"Inferred label: \" + str(title))"
   ]
  },
  {
   "source": [
    "#### K-Means Tools"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_centroids(X_train, k, centroids_map={}):\n",
    "    # initialize centroids with random value\n",
    "    for k_val, train_data in enumerate(random.choices(X_train, k=k)):\n",
    "        centroids_map[k_val] = train_data\n",
    "    return centroids_map\n",
    "\n",
    "def update_centroids(cluster_map, centroids_map={}):\n",
    "    # tune centroids based on the updated cluster info\n",
    "    for key, val in cluster_map.items():\n",
    "        centroids_map[key] = sum(val) / len(val)\n",
    "    return centroids_map\n",
    "\n",
    "def k_means_clustering(X_train, y_train, k, max_iter):\n",
    "    final_cluster_map, centroids_map = {}, {}\n",
    "    old_cluster_distances_sum = float('inf')\n",
    "    centroids_map = initial_centroids(X_train, k)\n",
    "    for i in range(max_iter):\n",
    "        centroids_val = list(centroids_map.values())\n",
    "        # compute pairwise minimum distance\n",
    "        cluster_labels, cluster_distances = pairwise_distances_argmin_min(X_train, centroids_val)\n",
    "\n",
    "        # set stop rule\n",
    "        if old_cluster_distances_sum - sum(cluster_distances) <= 0.001:\n",
    "            print('converged at iter', i)\n",
    "            break\n",
    "        old_cluster_distances_sum = sum(cluster_distances)\n",
    "\n",
    "        cluster_map = defaultdict(list)\n",
    "        label_cluster_map = defaultdict(list)\n",
    "        \n",
    "        # key: cluster label / val: mnist label value within the cluster\n",
    "        for cluster_label, train_label in zip(cluster_labels, y_train):\n",
    "            label_cluster_map[cluster_label].append(train_label)\n",
    "\n",
    "        for x_train_val, cluster_label in zip(X_train, cluster_labels):\n",
    "            cluster_map[cluster_label].append(x_train_val)\n",
    "\n",
    "        # tune centroids given the updated cluster map\n",
    "        centroids_map = update_centroids(cluster_map)\n",
    "    return label_cluster_map, cluster_distances\n",
    "\n",
    "def evaluate_purity_score(cluster_distances, label_cluster_map):\n",
    "    sum_count = 0\n",
    "    for label, value in label_cluster_map.items():\n",
    "        most_frequent_label_count = Counter(value).most_common(1)[0][1]\n",
    "        sum_count += most_frequent_label_count\n",
    "    purity_score = sum_count / len(X_train) * 100\n",
    "    print(\"evaluated objective is {}\".format(sum(cluster_distances)))\n",
    "    print(\"evaluated purity score is {}%\".format(purity_score))\n",
    "\n",
    "def evaluate_gini_index(X_train, label_cluster_map):\n",
    "    sum_val = 0\n",
    "    for label, val in label_cluster_map.items():\n",
    "        sum_val += (Counter(val).most_common(1)[0][1] / len(X_train)) ** 2\n",
    "    return 1 - sum_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "converged at iter 56\nevaluated objective is 41971.14899429267\nevaluated purity score is 39.82333333333333%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9662455666666667"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "label_cluster_map, cluster_distances = k_means_clustering(X_train, y_train, k=5, max_iter=100)\n",
    "evaluate_purity_score(cluster_distances, label_cluster_map)\n",
    "evaluate_gini_index(X_train, label_cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "converged at iter 57\nevaluated objective is 39360.4540000393\nevaluated purity score is 61.00833333333333%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9609515402777777"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "label_cluster_map, cluster_distances = k_means_clustering(X_train, y_train, k=10, max_iter=100)\n",
    "evaluate_purity_score(cluster_distances, label_cluster_map)\n",
    "evaluate_gini_index(X_train, label_cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "converged at iter 71\nevaluated objective is 37199.58953827097\nevaluated purity score is 72.97666666666667%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9717085377777778"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "label_cluster_map, cluster_distances = k_means_clustering(X_train, y_train, k=20, max_iter=100)\n",
    "evaluate_purity_score(cluster_distances, label_cluster_map)\n",
    "evaluate_gini_index(X_train, label_cluster_map)"
   ]
  },
  {
   "source": [
    "## Section B - Fashion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 784)\n(60000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train) , (X_test, y_test)= fashion_mnist.load_data()\n",
    "\n",
    "X_train = normalize(X_train.reshape(60000, 784))\n",
    "X_test = normalize(X_test.reshape(10000, 784))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "converged at iter 27\nevaluated objective is 28453.509329888904\nevaluated purity score is 45.81166666666667%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9579964941666667"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "label_cluster_map, cluster_distances = k_means_clustering(X_train, y_train, k=5, max_iter=100)\n",
    "evaluate_purity_score(cluster_distances, label_cluster_map)\n",
    "evaluate_gini_index(X_train, label_cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "converged at iter 32\nevaluated objective is 26448.393157079583\nevaluated purity score is 61.95166666666667%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9570461919444444"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "label_cluster_map, cluster_distances = k_means_clustering(X_train, y_train, k=10, max_iter=100)\n",
    "evaluate_purity_score(cluster_distances, label_cluster_map)\n",
    "evaluate_gini_index(X_train, label_cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "converged at iter 29\nevaluated objective is 24911.90426408329\nevaluated purity score is 63.92333333333333%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9734539794444445"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "label_cluster_map, cluster_distances = k_means_clustering(X_train, y_train, k=20, max_iter=100)\n",
    "evaluate_purity_score(cluster_distances, label_cluster_map)\n",
    "evaluate_gini_index(X_train, label_cluster_map)"
   ]
  },
  {
   "source": [
    "## Section C - 20 NG"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "newsgroups_dataset = fetch_20newsgroups(subset='train')\n",
    "train_data = newsgroups_dataset.data\n",
    "train_label = newsgroups_dataset.target\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_data = vectorizer.fit_transform(train_data)\n",
    "train_data = np.array(normalize(train_data.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[:5000]\n",
    "y_train = train_label[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 784)\n(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "converged at iter 35\nevaluated objective is 41960.91842235273\nevaluated purity score is 37.79%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.970444185"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "label_cluster_map, cluster_distances = k_means_clustering(X_train, y_train, k=5, max_iter=200)\n",
    "evaluate_purity_score(cluster_distances, label_cluster_map)\n",
    "evaluate_gini_index(X_train, label_cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "evaluated objective is 39450.29859381385\nevaluated purity score is 55.655%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9657038086111112"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "label_cluster_map, cluster_distances = k_means_clustering(X_train, y_train, k=10, max_iter=50)\n",
    "evaluate_purity_score(cluster_distances, label_cluster_map)\n",
    "evaluate_gini_index(X_train, label_cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "evaluated objective is 37103.73234474686\nevaluated purity score is 71.36333333333333%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9711141622222222"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "label_cluster_map, cluster_distances = k_means_clustering(X_train, y_train, k=20, max_iter=50)\n",
    "evaluate_purity_score(cluster_distances, label_cluster_map)\n",
    "evaluate_gini_index(X_train, label_cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}