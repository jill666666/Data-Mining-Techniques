{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Problem 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "source": [
    "## Problem 2\n",
    "### MNIST dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) , (X_test, y_test)= keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.6607 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.4203 - val_sparse_categorical_accuracy: 0.8515\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3971 - sparse_categorical_accuracy: 0.8570 - val_loss: 0.3801 - val_sparse_categorical_accuracy: 0.8644\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3477 - sparse_categorical_accuracy: 0.8722 - val_loss: 0.3517 - val_sparse_categorical_accuracy: 0.8740\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3173 - sparse_categorical_accuracy: 0.8822 - val_loss: 0.3351 - val_sparse_categorical_accuracy: 0.8798\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.2954 - sparse_categorical_accuracy: 0.8900 - val_loss: 0.3328 - val_sparse_categorical_accuracy: 0.8759\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.2806 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.3278 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.2649 - sparse_categorical_accuracy: 0.9030 - val_loss: 0.3445 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.2561 - sparse_categorical_accuracy: 0.9044 - val_loss: 0.3364 - val_sparse_categorical_accuracy: 0.8751\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.2455 - sparse_categorical_accuracy: 0.9080 - val_loss: 0.3062 - val_sparse_categorical_accuracy: 0.8907\n",
      "Epoch 10/10\n",
      "127/782 [===>..........................] - ETA: 1s - loss: 0.2345 - sparse_categorical_accuracy: 0.9093"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    validation_data=val_dataset\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 1ms/step - loss: 0.3601 - sparse_categorical_accuracy: 0.8749\n",
      "\n",
      "Predicted label vs. actual label\n",
      "9 vs. 9\n",
      "2 vs. 2\n",
      "1 vs. 1\n",
      "1 vs. 1\n",
      "6 vs. 6\n",
      "1 vs. 1\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate on test data')\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print('\\nPredicted label vs. actual label')\n",
    "for i in range(6):\n",
    "    predicted_label, actual_label = np.argmax(predictions[i]), int(y_test[i])\n",
    "    print('{} vs. {}'.format(predicted_label, actual_label))"
   ]
  },
  {
   "source": [
    "### 20NG Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_train shape - (11314, 130107)\ny_train shape - (11314,)\nX_test shape - (7532, 130107)\ny_test shape - (7532,)\nLabels - {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = fetch_20newsgroups(subset='train')\n",
    "X_test = fetch_20newsgroups(subset='test')\n",
    "y_train = X_train.target\n",
    "y_test = X_test.target\n",
    "\n",
    "LABELS = set(y_train)\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train.data).todense()\n",
    "X_test = vectorizer.transform(X_test.data).todense()\n",
    "print('X_train shape -', X_train.shape)\n",
    "print('y_train shape -', y_train.shape)\n",
    "print('X_test shape -', X_test.shape)\n",
    "print('y_test shape -', y_test.shape)\n",
    "print('Labels -', LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(20, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/6\n",
      "177/177 [==============================] - 17s 91ms/step - loss: 2.6811 - sparse_categorical_accuracy: 0.4063\n",
      "Epoch 2/6\n",
      "177/177 [==============================] - 14s 80ms/step - loss: 0.8608 - sparse_categorical_accuracy: 0.9163\n",
      "Epoch 3/6\n",
      "177/177 [==============================] - 14s 80ms/step - loss: 0.2438 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 4/6\n",
      "177/177 [==============================] - 16s 91ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 5/6\n",
      "177/177 [==============================] - 19s 106ms/step - loss: 0.0418 - sparse_categorical_accuracy: 0.9935\n",
      "Epoch 6/6\n",
      "177/177 [==============================] - 19s 108ms/step - loss: 0.0183 - sparse_categorical_accuracy: 0.9964\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=6,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluate on test data\n",
      "59/59 [==============================] - 6s 75ms/step - loss: 0.5691 - sparse_categorical_accuracy: 0.8517\n",
      "\n",
      "Predicted label vs. actual label\n",
      "7 vs. 7\n",
      "5 vs. 5\n",
      "0 vs. 0\n",
      "17 vs. 17\n",
      "0 vs. 19\n",
      "13 vs. 13\n",
      "15 vs. 15\n",
      "2 vs. 15\n",
      "5 vs. 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print('\\nPredicted label vs. actual label')\n",
    "for i in range(9):\n",
    "    predicted_label, actual_label = np.argmax(predictions[i]), int(y_test[i])\n",
    "    print('{} vs. {}'.format(predicted_label, actual_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    predicted_labels.append(np.argmax(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8516994158258099"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predicted_labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}